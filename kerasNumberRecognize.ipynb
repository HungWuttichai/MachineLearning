{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, AveragePooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defind parameter\n",
    "os.chdir(\"C:/Users/wutti/number/\")\n",
    "\n",
    "dataset = 120\n",
    "num_test = 24\n",
    "\n",
    "batch_size = 20\n",
    "n_classes = 10\n",
    "epch = 100\n",
    "\n",
    "img_size = 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "x_train = []\n",
    "x_test = []\n",
    "\n",
    "for category in range(dataset):\n",
    "        try:\n",
    "            name = 'train/number ('+str(category)+').jpg'\n",
    "            img_array = cv2.imread(name)/255.0\n",
    "            new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            x_train.append(new_array)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "for category in range(num_test):\n",
    "        try:\n",
    "            name = 'test/number ('+str(category)+').jpg'\n",
    "            img_array = cv2.imread(name)/255.0 # cv2.IMREAD_GRAYSCALE\n",
    "            new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            x_test.append(new_array)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "X_train = np.asarray(x_train).astype('float32')\n",
    "y_train = ((np.arange(dataset) % 10) / 1.0).astype('float32')\n",
    "X_test = np.asarray(x_test).astype('float32')\n",
    "y_test = (np.array([2, 9, 5, 7, 2, 3, 7, 4, 0, 9, 8, 5, 5, 0, 8, 7, 2, 4, 3, 5, 3, 2, 7, 3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 24 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 2.4964 - acc: 0.0750 - val_loss: 2.2923 - val_acc: 0.1667\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.16667, saving model to weights.best.hdf5\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 2.3106 - acc: 0.1083 - val_loss: 2.3011 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.16667\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 2.3063 - acc: 0.0667 - val_loss: 2.3008 - val_acc: 0.1667\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.16667 to 0.16667, saving model to weights.best.hdf5\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 2.3010 - acc: 0.1333 - val_loss: 2.2994 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.16667\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 2.2959 - acc: 0.1250 - val_loss: 2.2830 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.16667\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 2.2742 - acc: 0.1750 - val_loss: 2.2149 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.16667 to 0.33333, saving model to weights.best.hdf5\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 2.1651 - acc: 0.2417 - val_loss: 1.7758 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.33333 to 0.50000, saving model to weights.best.hdf5\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.7354 - acc: 0.4583 - val_loss: 1.4677 - val_acc: 0.4583\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.50000\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 1.3976 - acc: 0.5917 - val_loss: 1.2635 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.50000 to 0.66667, saving model to weights.best.hdf5\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 1.1455 - acc: 0.6417 - val_loss: 1.3003 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.66667\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.8450 - acc: 0.7083 - val_loss: 1.0402 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.66667\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.5782 - acc: 0.8417 - val_loss: 0.9161 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.66667 to 0.70833, saving model to weights.best.hdf5\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.4003 - acc: 0.8167 - val_loss: 1.2495 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.70833\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.3292 - acc: 0.9083 - val_loss: 1.4162 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.70833\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.3570 - acc: 0.8500 - val_loss: 1.2779 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.70833\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1980 - acc: 0.9167 - val_loss: 1.3743 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.70833\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1793 - acc: 0.9333 - val_loss: 1.6406 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.70833\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2627 - acc: 0.9667 - val_loss: 1.7314 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.70833\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0599 - acc: 0.9833 - val_loss: 1.9538 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.70833 to 0.70833, saving model to weights.best.hdf5\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0602 - acc: 0.9833 - val_loss: 1.5656 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.70833\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1239 - acc: 0.9667 - val_loss: 1.2352 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.70833\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.1022 - acc: 0.9667 - val_loss: 1.7459 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.70833\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0565 - acc: 0.9667 - val_loss: 1.6728 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.70833\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0475 - acc: 0.9917 - val_loss: 1.7331 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.70833\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0644 - acc: 0.9833 - val_loss: 1.6226 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.70833\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0470 - acc: 0.9750 - val_loss: 1.7578 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.70833\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0327 - acc: 0.9833 - val_loss: 1.7903 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.70833\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0717 - acc: 0.9750 - val_loss: 2.4341 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.70833\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0861 - acc: 0.9667 - val_loss: 2.5504 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.70833\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0862 - acc: 0.9583 - val_loss: 1.7528 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.70833 to 0.70833, saving model to weights.best.hdf5\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0402 - acc: 0.9833 - val_loss: 1.2526 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.70833\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0454 - acc: 0.9833 - val_loss: 1.3638 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.70833 to 0.79167, saving model to weights.best.hdf5\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0098 - acc: 0.9917 - val_loss: 2.1766 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.79167\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0417 - acc: 0.9750 - val_loss: 2.1752 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.79167\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0190 - acc: 0.9917 - val_loss: 1.7139 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.79167\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0495 - acc: 0.9833 - val_loss: 1.4815 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.79167\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 1.7231 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.79167\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0176 - acc: 0.9917 - val_loss: 2.2841 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.79167\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4883 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.79167\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.0171 - acc: 0.9917 - val_loss: 2.5317 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.79167\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0182 - acc: 0.9833 - val_loss: 2.6385 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.79167\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.1191 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.79167\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.0622 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.79167\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0249 - acc: 0.9917 - val_loss: 2.4661 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.79167\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0595 - acc: 0.9750 - val_loss: 2.6496 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.79167\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.0626 - acc: 0.9833 - val_loss: 3.6373 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.79167\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1331 - acc: 0.9667 - val_loss: 2.1807 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.79167\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.3042 - acc: 0.9583 - val_loss: 2.6113 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.79167\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.3353 - acc: 0.9000 - val_loss: 1.8689 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.79167\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2542 - acc: 0.8833 - val_loss: 1.7532 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.79167\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0981 - acc: 0.9417 - val_loss: 1.7252 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.79167\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1516 - acc: 0.9583 - val_loss: 1.6093 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.79167\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.2553 - acc: 0.9333 - val_loss: 1.4035 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.79167\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0776 - acc: 0.9750 - val_loss: 1.4801 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.79167\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0596 - acc: 0.9833 - val_loss: 1.1495 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.79167\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 1.3470 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.79167\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.7442 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.79167\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 1.9152 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.79167\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0114 - acc: 0.9917 - val_loss: 1.7896 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.79167\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.5341 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.79167\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0536 - acc: 0.9917 - val_loss: 2.0388 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.79167\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 2.3310 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.79167\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 2.4547 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.79167\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0209 - acc: 0.9917 - val_loss: 2.1251 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.79167\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.0307 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.79167\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.0996 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.79167\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.2183 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.79167\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 2.1866 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.79167\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0161 - acc: 0.9917 - val_loss: 2.4963 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.79167\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0136 - acc: 0.9917 - val_loss: 2.1927 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.79167\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 3.9819e-04 - acc: 1.0000 - val_loss: 2.2215 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.79167\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 4.0491e-04 - acc: 1.0000 - val_loss: 2.3546 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.79167\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.1116 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.79167\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.0039 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.79167\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.0939 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.79167\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 7.9451e-04 - acc: 1.0000 - val_loss: 2.3979 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.79167\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 8.8904e-04 - acc: 1.0000 - val_loss: 2.6414 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.79167\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 3.8696e-04 - acc: 1.0000 - val_loss: 2.7947 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.79167\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0179 - acc: 0.9917 - val_loss: 2.0911 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.79167\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0130 - acc: 0.9917 - val_loss: 1.9482 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.79167\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4295 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.79167\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.4211 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.79167\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.9334 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.79167\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.8364 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.79167\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 4.0778e-04 - acc: 1.0000 - val_loss: 1.8103 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.79167\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 9.4302e-04 - acc: 1.0000 - val_loss: 1.9189 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.79167\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 5s 39ms/step - loss: 3.7994e-04 - acc: 1.0000 - val_loss: 2.0587 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.79167\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0405 - acc: 0.9917 - val_loss: 2.0406 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.79167\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0800 - acc: 0.9833 - val_loss: 1.7475 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.79167\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0097 - acc: 0.9917 - val_loss: 1.9644 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.79167\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.0988 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.79167\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0094 - acc: 0.9917 - val_loss: 2.1666 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.79167\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0123 - acc: 0.9917 - val_loss: 2.4203 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.79167\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 1.5871e-04 - acc: 1.0000 - val_loss: 2.3530 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.79167\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0408 - acc: 0.9917 - val_loss: 2.3209 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.79167\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.4540 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.79167\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.2647 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.79167\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.0231 - acc: 0.9917 - val_loss: 2.5091 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.79167\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 2.6020e-04 - acc: 1.0000 - val_loss: 2.7137 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.79167\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1094 - acc: 0.9917 - val_loss: 2.5321 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.79167\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#train\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=int(epch), batch_size=batch_size, \n",
    "            verbose=1, validation_data=(X_test, y_test), callbacks=callbacks_list)\n",
    "\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "model.save('model_number.model')\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n",
      "Test_accuracy: 83.33 %\n",
      "Predicted [2 9 5 7 2 6 7 4 0 5 8 5 8 0 8 7 2 4 3 5 3 8 7 3]\n"
     ]
    }
   ],
   "source": [
    "#test model\n",
    "new_model = load_model('model_number.model')\n",
    "predictions = new_model.predict(X_test)\n",
    "result = np.argmax(predictions, axis=1)\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test_accuracy: %0.2f' % (scores[1]*100), '%')\n",
    "print(\"Predicted\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test one picture\n",
    "one_model = load_model('model_number.model')\n",
    "\n",
    "one_name = 'test/number (25).jpg'\n",
    "one_img = cv2.imread(one_name)/255.0 \n",
    "one_array = cv2.resize(one_img, (img_size, img_size))\n",
    "x_test1 = np.asarray(one_array).astype('float32')\n",
    "X_test1 = x_test1.reshape((1,28,28,3))\n",
    "one_predict = one_model.predict(X_test1)\n",
    "one_result = np.argmax(one_predict, axis=1)\n",
    "print(\"Predicted :\", one_result)\n",
    "plt.imshow(one_img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA (60, 28, 28, 3)\n",
      "BB (60,)\n",
      "AA (70, 28, 28, 3)\n",
      "BB (70,)\n",
      "AA (70, 28, 28, 3)\n",
      "BB (70,)\n",
      "AA (70, 28, 28, 3)\n",
      "BB (70,)\n"
     ]
    }
   ],
   "source": [
    "for (fold, val_idx) in enumerate(folds):\n",
    "    #print(\"A\", trin_idx)\n",
    "    #print(\"B\", val_idx)\n",
    "    #print(\"train idx\", val_idx[0])\n",
    "    #print(\"test idx\", val_idx[1])\n",
    "    train_idx = val_idx[0]\n",
    "    test_idx = val_idx[1]\n",
    "    print(\"AA\", X_train[train_idx].shape)\n",
    "    print(\"BB\", y_train[train_idx].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
