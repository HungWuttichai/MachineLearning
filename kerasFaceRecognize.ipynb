{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.datasets import cifar10\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, AveragePooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "os.chdir(\"C:/Users/wutti/face/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 50\n",
    "n_classes = 10\n",
    "epch = 10\n",
    "batch_size = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 50, 50, 3)\n",
      "(280,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(61, 50, 50, 3)\n",
      "(61,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predict_person = {0:\"unknown\", 1:\"Hung\"}\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "i = 0\n",
    "fold_train = os.listdir(\"train\")\n",
    "for cate_train in fold_train:\n",
    "    img_train = os.listdir(\"train/\"+cate_train)\n",
    "    for numImg_train in img_train:\n",
    "        try:\n",
    "            name = 'train/'+cate_train+'/'+numImg_train\n",
    "            img_array = cv2.imread(name)/255.0\n",
    "            new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            x_train.append(new_array)\n",
    "            y_train.append(i)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    i += 1\n",
    "\n",
    "j = 0\n",
    "fold_test = os.listdir(\"test\")\n",
    "for cate_test in fold_train:\n",
    "    img_test = os.listdir(\"test/\"+cate_test)\n",
    "    for numImg_test in img_test:\n",
    "        try:\n",
    "            name = 'test/'+cate_test+'/'+numImg_test\n",
    "            img_array = cv2.imread(name)/255.0\n",
    "            new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            x_test.append(new_array)\n",
    "            y_test.append(j)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    j += 1\n",
    "\n",
    "X_train = np.asarray(x_train).astype('float32')\n",
    "Y_train = np.asarray(y_train).astype('int')\n",
    "X_test = np.asarray(x_test).astype('float32')\n",
    "Y_test = np.asarray(y_test).astype('int')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_train)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280 samples, validate on 61 samples\n",
      "Epoch 1/10\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 1.2526 - acc: 0.4607 - val_loss: 0.7421 - val_acc: 0.3770\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.37705, saving model to weights.best.hdf5\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 2s 7ms/step - loss: 0.7631 - acc: 0.6429 - val_loss: 0.5333 - val_acc: 0.7377\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.37705 to 0.73770, saving model to weights.best.hdf5\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.3882 - acc: 0.8393 - val_loss: 0.1173 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73770 to 0.95082, saving model to weights.best.hdf5\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0666 - acc: 0.9643 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95082 to 1.00000, saving model to weights.best.hdf5\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 4.5403e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 1.00000\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.5906e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 1.00000\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 9.0713e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 1.00000\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 3.4981e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 1.00000\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 1.5335e-04 - acc: 1.0000 - val_loss: 4.7702e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 1.00000\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0028 - acc: 0.9964 - val_loss: 8.2289e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 1.00000\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) \n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#train\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=epch, batch_size=batch_size, \n",
    "            verbose=1, validation_data=(X_test, Y_test), callbacks=callbacks_list)\n",
    "\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "model.save('faceRecognize.model')\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wutti\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\wutti\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\wutti\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "61/61 [==============================] - 0s 2ms/step\n",
      "Test accuracy: 1.0\n",
      "Predicted [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "new_model = load_model('faceRecognize.model')\n",
    "predictions = new_model.predict(X_test)\n",
    "\n",
    "scores = new_model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "print(\"Predicted\", np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "#mouth_cascade = cv2.CascadeClassifier('haarcascade_mcs_mouth.xml')\n",
    "#smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "i = 150\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(\"train/hung/face (%d).jpg\" %(i+1), roi_color)\n",
    "        time.sleep(0.3)\n",
    "        i += 1\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        #eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        #for (ex,ey,ew,eh) in eyes:\n",
    "        #    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            \n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wutti\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\wutti\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\wutti\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# test video\n",
    "\n",
    "predict_person = {0:\"unknown\", 1:\"Hung\"}\n",
    "new_model = load_model('faceRecognize.model')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2\n",
    "try:\n",
    "    while(True):\n",
    "        ret, img = cap.read()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "            temp1 = cv2.resize(roi_color,(img_size,img_size))/255.00\n",
    "            temp2 = np.asarray(temp1).astype('float32')\n",
    "            roi_face = temp2.reshape((1,img_size,img_size,3))\n",
    "            predictions = new_model.predict(roi_face)\n",
    "            result_predict = np.argmax(predictions, axis=1)\n",
    "            \n",
    "            cv2.putText(img, predict_person[result_predict[0]], (x+w,y+h), font, fontScale,fontColor,lineType)\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "        cv2.imshow('img',img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except Exception as e:\n",
    "    cap.release()\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
